{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Riroaki/CapsNet.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3Jc-23LJYmy",
        "outputId": "6d1b4464-5ba9-46b2-f628-6b0f53f0eba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'CapsNet' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "J2dYngN0Jb5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Pfd-4WsXJfxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def squash(x, dim=-1):\n",
        "    squared_norm = (x ** 2).sum(dim=dim, keepdim=True)\n",
        "    scale = squared_norm / (1 + squared_norm)\n",
        "    return scale * x / (squared_norm.sqrt() + 1e-8)"
      ],
      "metadata": {
        "id": "iynY2acdJiLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Residual_Block(nn.Module):\n",
        "\n",
        "    def __init__(self, in_dim, mid_dim, out_dim):\n",
        "      super(Residual_Block,self).__init__()\n",
        "        # Residual Block\n",
        "      self.residual_block = nn.Sequential(\n",
        "                nn.Conv2d(in_dim, mid_dim, kernel_size=3, padding=1),\n",
        "                nn.ReLU,\n",
        "                nn.Conv2d(mid_dim, out_dim, kernel_size=3, padding=1),\n",
        "            )\n",
        "      self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "       out = self. residual_block(x)  # F(x)\n",
        "       out = out + x  # F(x) + x\n",
        "       out = self.relu(out)\n",
        "       return out"
      ],
      "metadata": {
        "id": "DOvoG36NKYeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PrimaryCaps(nn.Module):\n",
        "    \"\"\"Primary capsule layer.\"\"\"\n",
        "\n",
        "    def __init__(self, num_conv_units, in_channels, out_channels, kernel_size, stride):\n",
        "        super(PrimaryCaps, self).__init__()\n",
        "\n",
        "        # Each conv unit stands for a single capsule.\n",
        "        self.conv = nn.Conv2d(in_channels=in_channels,\n",
        "                              out_channels=out_channels * num_conv_units,\n",
        "                              kernel_size=kernel_size,\n",
        "                              stride=stride)\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shape of x: (batch_size, in_channels, height, weight)\n",
        "        # Shape of out: out_capsules * (batch_size, out_channels, height, weight)\n",
        "        out = self.conv(x)\n",
        "        # Flatten out: (batch_size, out_capsules * height * weight, out_channels)\n",
        "        batch_size = out.shape[0]\n",
        "        return squash(out.contiguous().view(batch_size, -1, self.out_channels), dim=-1)"
      ],
      "metadata": {
        "id": "O5xQMsaKJlz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DigitCaps(nn.Module):\n",
        "    \"\"\"Digit capsule layer.\"\"\"\n",
        "\n",
        "    def __init__(self, in_dim, in_caps, out_caps, out_dim, num_routing):\n",
        "        \"\"\"\n",
        "        Initialize the layer.\n",
        "        Args:\n",
        "            in_dim: \t\tDimensionality of each capsule vector.\n",
        "            in_caps: \t\tNumber of input capsules if digits layer.\n",
        "            out_caps: \t\tNumber of capsules in the capsule layer\n",
        "            out_dim: \t\tDimensionality, of the output capsule vector.\n",
        "            num_routing:\tNumber of iterations during routing algorithm\n",
        "        \"\"\"\n",
        "        super(DigitCaps, self).__init__()\n",
        "        self.in_dim = in_dim\n",
        "        self.in_caps = in_caps\n",
        "        self.out_caps = out_caps\n",
        "        self.out_dim = out_dim\n",
        "        self.num_routing = num_routing\n",
        "        self.device = device\n",
        "        self.W = nn.Parameter(0.01 * torch.randn(1, out_caps, in_caps, out_dim, in_dim),\n",
        "                              requires_grad=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        # (batch_size, in_caps, in_dim) -> (batch_size, 1, in_caps, in_dim, 1)\n",
        "        x = x.unsqueeze(1).unsqueeze(4)\n",
        "        # W @ x =\n",
        "        # (1, out_caps, in_caps, out_dim, in_dim) @ (batch_size, 1, in_caps, in_dim, 1) =\n",
        "        # (batch_size, out_caps, in_caps, out_dims, 1)\n",
        "        u_hat = torch.matmul(self.W, x)\n",
        "        # (batch_size, out_caps, in_caps, out_dim)\n",
        "        u_hat = u_hat.squeeze(-1)\n",
        "        # detach u_hat during routing iterations to prevent gradients from flowing\n",
        "        temp_u_hat = u_hat.detach()\n",
        "\n",
        "        b = torch.zeros(batch_size, self.out_caps, self.in_caps, 1).to(self.device)\n",
        "        for route_iter in range(self.num_routing - 1):\n",
        "            # (batch_size, out_caps, in_caps, 1) -> Softmax along out_caps\n",
        "            c = b.softmax(dim=1)\n",
        "\n",
        "            # element-wise multiplication\n",
        "            # (batch_size, out_caps, in_caps, 1) * (batch_size, in_caps, out_caps, out_dim) ->\n",
        "            # (batch_size, out_caps, in_caps, out_dim) sum across in_caps ->\n",
        "            # (batch_size, out_caps, out_dim)\n",
        "            s = (c * temp_u_hat).sum(dim=2)\n",
        "            # apply \"squashing\" non-linearity along out_dim\n",
        "            v = squash(s)\n",
        "            # dot product agreement between the current output vj and the prediction uj|i\n",
        "            # (batch_size, out_caps, in_caps, out_dim) @ (batch_size, out_caps, out_dim, 1)\n",
        "            # -> (batch_size, out_caps, in_caps, 1)\n",
        "            uv = torch.matmul(temp_u_hat, v.unsqueeze(-1))\n",
        "            b += uv\n",
        "\n",
        "        # last iteration is done on the original u_hat, without the routing weights update\n",
        "        c = b.softmax(dim=1)\n",
        "        s = (c * u_hat).sum(dim=2)\n",
        "        # apply \"squashing\" non-linearity along out_dim\n",
        "        v = squash(s)\n",
        "\n",
        "        return v"
      ],
      "metadata": {
        "id": "XJoh9thJJmrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CapsNet(nn.Module):\n",
        "    \"\"\"Basic implementation of capsule network layer.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CapsNet, self).__init__()\n",
        "\n",
        "        # Conv2d layer1\n",
        "        self.conv1 = nn.Conv2d(1, 32, 9)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Batch Normalization1\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "        # Conv2d layer2\n",
        "        self.conv2 = nn.Conv2d(32, 64, 9)\n",
        "        self.sigmoid2 = nn.Sigmoid()\n",
        "\n",
        "        # Batch Normalization2\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        # Conv2d layer3\n",
        "        self.conv3 = nn.Conv2d(64, 256, 9)\n",
        "        self.relu3 = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Primary capsule\n",
        "        self.primary_caps = PrimaryCaps(num_conv_units=32,\n",
        "                                        in_channels=256,\n",
        "                                        out_channels=8,\n",
        "                                        kernel_size=9,\n",
        "                                        stride=2)\n",
        "\n",
        "        # Digit capsule\n",
        "        self.digit_caps = DigitCaps(in_dim=8,\n",
        "                                    in_caps=32 * 6 * 6,\n",
        "                                    out_caps=7,\n",
        "                                    out_dim=16,\n",
        "                                    num_routing=3)\n",
        "\n",
        "        # Reconstruction layer\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(16 * 7, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 1600),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1600, 2304),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(2304, 1936),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu1(self.conv1(x))\n",
        "        out = self.bn1(out)\n",
        "        out = self.sigmoid2(self.conv2(out))\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu3(self.conv3(out))\n",
        "        out = self.primary_caps(out)\n",
        "        out = self.digit_caps(out)\n",
        "\n",
        "        # Shape of logits: (batch_size, out_capsules)\n",
        "        logits = torch.norm(out, dim=-1)\n",
        "        pred = torch.eye(7).to(device).index_select(dim=0, index=torch.argmax(logits, dim=1))\n",
        "\n",
        "        # Reconstruction\n",
        "        batch_size = out.shape[0]\n",
        "        reconstruction = self.decoder((out * pred.unsqueeze(2)).contiguous().view(batch_size, -1))\n",
        "\n",
        "        return logits, reconstruction"
      ],
      "metadata": {
        "id": "h1x0ejpcJq7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CapsuleLoss(nn.Module):\n",
        "    \"\"\"Combine margin loss & reconstruction loss of capsule network.\"\"\"\n",
        "\n",
        "    def __init__(self, upper_bound=0.9, lower_bound=0.1, lmda=0.5):\n",
        "        super(CapsuleLoss, self).__init__()\n",
        "        self.upper = upper_bound\n",
        "        self.lower = lower_bound\n",
        "        self.lmda = lmda\n",
        "        self.reconstruction_loss_scalar = 5e-3\n",
        "        self.mse = nn.MSELoss(reduction='sum')\n",
        "\n",
        "    def forward(self, images, labels, logits, reconstructions):\n",
        "        # Shape of left / right / labels: (batch_size, num_classes)\n",
        "        left = (self.upper - logits).relu() ** 2  # True negative\n",
        "        right = (logits - self.lower).relu() ** 2  # False positive\n",
        "        margin_loss = torch.sum(labels * left) + self.lmda * torch.sum((1 - labels) * right)\n",
        "\n",
        "        # Reconstruction loss\n",
        "        reconstruction_loss = self.mse(reconstructions.contiguous().view(images.shape), images)\n",
        "        self.reconstruction_loss_scalar *= 1.001\n",
        "\n",
        "        # Combine two losses\n",
        "        return margin_loss + self.reconstruction_loss_scalar * reconstruction_loss"
      ],
      "metadata": {
        "id": "UUoKMaUyJvYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1m06cGemJx4r",
        "outputId": "3fdd1fed-cee4-4a30-ddef-ec4247236208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import transforms\n",
        "from torch.optim import Adam"
      ],
      "metadata": {
        "id": "efRNMq0nJz9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "GLv66B0UJ3km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Load model\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "    model = CapsNet().to(device)\n",
        "    criterion = CapsuleLoss()\n",
        "    optimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.96)\n",
        "\n",
        "    # Load data\n",
        "    transform = transforms.Compose([\n",
        "        # shift by 2 pixels in either direction with zero padding.\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.RandomCrop(44, padding=1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "    BATCH_SIZE = 128\n",
        "    trainset = torchvision.datasets.ImageFolder(root=\"/content/drive/MyDrive/wiset/train\", transform=transform)\n",
        "    train_loader = DataLoader(trainset, batch_size=BATCH_SIZE, num_workers=4, shuffle=True)\n",
        "    testset = torchvision.datasets.ImageFolder(root=\"/content/drive/MyDrive/wiset/test\", transform=transform)\n",
        "    test_loader = DataLoader(testset, batch_size=BATCH_SIZE, num_workers=4, shuffle=True)\n",
        "\n",
        "    # Train\n",
        "    EPOCHES = 10\n",
        "    model.train()\n",
        "    for ep in range(EPOCHES):\n",
        "        batch_id = 10\n",
        "        correct, total, total_loss = 0, 0, 0.\n",
        "        for images, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            images = images.to(device)\n",
        "            labels = torch.eye(7).index_select(dim=0, index=labels).to(device)\n",
        "            logits, reconstruction = model(images)\n",
        "\n",
        "            # Compute loss & accuracy\n",
        "            loss = criterion(images, labels, logits, reconstruction)\n",
        "            correct += torch.sum(\n",
        "                torch.argmax(logits, dim=1) == torch.argmax(labels, dim=1)).item()\n",
        "            total += len(labels)\n",
        "            accuracy = correct / total\n",
        "            total_loss += loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            batch_id += 1\n",
        "        scheduler.step(ep)\n",
        "        print('Total loss for epoch {}: {}, Accuracy: {}'.format(ep+1, total_loss, accuracy))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzmsTQNGJ58f",
        "outputId": "beec0ef9-7ca2-4332-d3d0-cd15f9d2543e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total loss for epoch 1: 237858.40625, Accuracy: 0.25679886685552406\n",
            "Total loss for epoch 2: 288460.65625, Accuracy: 0.3435198300283286\n",
            "Total loss for epoch 3: 356255.96875, Accuracy: 0.3896954674220963\n",
            "Total loss for epoch 4: 441090.75, Accuracy: 0.4244334277620397\n",
            "Total loss for epoch 5: 547184.0625, Accuracy: 0.44975212464589237\n",
            "Total loss for epoch 6: 679452.5625, Accuracy: 0.47694759206798865\n",
            "Total loss for epoch 7: 844822.375, Accuracy: 0.4992209631728045\n",
            "Total loss for epoch 8: 1050425.75, Accuracy: 0.524185552407932\n",
            "Total loss for epoch 9: 1307027.875, Accuracy: 0.5449362606232294\n",
            "Total loss for epoch 10: 1627966.875, Accuracy: 0.5717776203966005\n"
          ]
        }
      ]
    }
  ]
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0955D7LeRmk",
        "outputId": "5965a00c-5430-49f0-a7d0-0fa4aa39d751"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CapsNet'...\n",
            "remote: Enumerating objects: 28, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 28 (delta 13), reused 24 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (28/28), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Riroaki/CapsNet.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BcGhwdbcPD2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQHOEWB3cSzH"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1jGgxQ0cbPm"
      },
      "outputs": [],
      "source": [
        "def squash(x, dim=-1):\n",
        "    squared_norm = (x ** 2).sum(dim=dim, keepdim=True)\n",
        "    scale = squared_norm / (1 + squared_norm)\n",
        "    return scale * x / (squared_norm.sqrt() + 1e-8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yZY8YENcdMd"
      },
      "outputs": [],
      "source": [
        "class PrimaryCaps(nn.Module):\n",
        "    \"\"\"Primary capsule layer.\"\"\"\n",
        "\n",
        "    def __init__(self, num_conv_units, in_channels, out_channels, kernel_size, stride):\n",
        "        super(PrimaryCaps, self).__init__()\n",
        "\n",
        "        # Each conv unit stands for a single capsule.\n",
        "        self.conv = nn.Conv2d(in_channels=3,\n",
        "                              out_channels=out_channels * num_conv_units,\n",
        "                              kernel_size=kernel_size,\n",
        "                              stride=stride)\n",
        "        self.out_channels = out_channels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvkGFQx3cgPr"
      },
      "outputs": [],
      "source": [
        "def forward(self, x):\n",
        "        # Shape of x: (batch_size, in_channels, height, weight)\n",
        "        # Shape of out: out_capsules * (batch_size, out_channels, height, weight)\n",
        "        out = self.conv(x)\n",
        "        # Flatten out: (batch_size, out_capsules * height * weight, out_channels)\n",
        "        batch_size = out.shape[0]\n",
        "        return squash(out.contiguous().view(batch_size, -1, self.out_channels), dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyzUfI_Scjkv"
      },
      "outputs": [],
      "source": [
        "class DigitCaps(nn.Module):\n",
        "    \"\"\"Digit capsule layer.\"\"\"\n",
        "\n",
        "    def __init__(self, in_dim, in_caps, out_caps, out_dim, num_routing):\n",
        "        \"\"\"\n",
        "        Initialize the layer.\n",
        "        Args:\n",
        "            in_dim: \t\tDimensionality of each capsule vector.\n",
        "            in_caps: \t\tNumber of input capsules if digits layer.\n",
        "            out_caps: \t\tNumber of capsules in the capsule layer\n",
        "            out_dim: \t\tDimensionality, of the output capsule vector.\n",
        "            num_routing:\tNumber of iterations during routing algorithm\n",
        "        \"\"\"\n",
        "        super(DigitCaps, self).__init__()\n",
        "        self.in_dim = in_dim\n",
        "        self.in_caps = in_caps\n",
        "        self.out_caps = out_caps\n",
        "        self.out_dim = out_dim\n",
        "        self.num_routing = num_routing\n",
        "        self.device = device\n",
        "        self.W = nn.Parameter(0.01 * torch.randn(1, out_caps, in_caps, out_dim, in_dim),\n",
        "                              requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBXNm_fucm4-"
      },
      "outputs": [],
      "source": [
        "def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        # (batch_size, in_caps, in_dim) -> (batch_size, 1, in_caps, in_dim, 1)\n",
        "        x = x.unsqueeze(1).unsqueeze(4)\n",
        "        # W @ x =\n",
        "        # (1, out_caps, in_caps, out_dim, in_dim) @ (batch_size, 1, in_caps, in_dim, 1) =\n",
        "        # (batch_size, out_caps, in_caps, out_dims, 1)\n",
        "        u_hat = torch.matmul(self.W, x)\n",
        "        # (batch_size, out_caps, in_caps, out_dim)\n",
        "        u_hat = u_hat.squeeze(-1)\n",
        "        # detach u_hat during routing iterations to prevent gradients from flowing\n",
        "        temp_u_hat = u_hat.detach()\n",
        "\n",
        "        b = torch.zeros(batch_size, self.out_caps, self.in_caps, 1).to(self.device)\n",
        "        for route_iter in range(self.num_routing - 1):\n",
        "            # (batch_size, out_caps, in_caps, 1) -> Softmax along out_caps\n",
        "            c = b.softmax(dim=1)\n",
        "\n",
        "            # element-wise multiplication\n",
        "            # (batch_size, out_caps, in_caps, 1) * (batch_size, in_caps, out_caps, out_dim) ->\n",
        "            # (batch_size, out_caps, in_caps, out_dim) sum across in_caps ->\n",
        "            # (batch_size, out_caps, out_dim)\n",
        "            s = (c * temp_u_hat).sum(dim=2)\n",
        "            # apply \"squashing\" non-linearity along out_dim\n",
        "            v = squash(s)\n",
        "            # dot product agreement between the current output vj and the prediction uj|i\n",
        "            # (batch_size, out_caps, in_caps, out_dim) @ (batch_size, out_caps, out_dim, 1)\n",
        "            # -> (batch_size, out_caps, in_caps, 1)\n",
        "            uv = torch.matmul(temp_u_hat, v.unsqueeze(-1))\n",
        "            b += uv\n",
        "\n",
        "        # last iteration is done on the original u_hat, without the routing weights update\n",
        "        c = b.softmax(dim=1)\n",
        "        s = (c * u_hat).sum(dim=2)\n",
        "        # apply \"squashing\" non-linearity along out_dim\n",
        "        v = squash(s)\n",
        "\n",
        "        return v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92R_CvgFdbT7"
      },
      "outputs": [],
      "source": [
        "class CapsNet(nn.Module):\n",
        "    \"\"\"Basic implementation of capsule network layer.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CapsNet, self).__init__()\n",
        "\n",
        "        # Conv2d layer1\n",
        "        self.conv1 = nn.Conv2d(1, 32, 9)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Batch Normalization1\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "        # Conv2d layer2\n",
        "        self.conv2 = nn.Conv2d(32, 64, 9)\n",
        "        self.sigmoid2 = nn.Sigmoid()\n",
        "\n",
        "        # Batch Normalization2\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        # Conv2d layer3\n",
        "        self.conv3 = nn.Conv2d(64, 256, 9)\n",
        "        self.relu3 = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Primary capsule\n",
        "        self.primary_caps = PrimaryCaps(num_conv_units=32,\n",
        "                                        in_channels=256,\n",
        "                                        out_channels=8,\n",
        "                                        kernel_size=9,\n",
        "                                        stride=2)\n",
        "\n",
        "        # Digit capsule\n",
        "        self.digit_caps = DigitCaps(in_dim=8,\n",
        "                                    in_caps=32 * 6 * 6,\n",
        "                                    out_caps=7,\n",
        "                                    out_dim=16,\n",
        "                                    num_routing=3)\n",
        "\n",
        "        # Reconstruction layer\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(16 * 10, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 1600),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1600, 2304),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(2304, 1936),\n",
        "            nn.Sigmoid())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qlo-sWXDdfwB"
      },
      "outputs": [],
      "source": [
        "def forward(self, x):\n",
        "        out = self.relu1(self.conv1(x))\n",
        "        out = self.bn1(out)\n",
        "        out = self.sigmoid2(self.conv2(out))\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu3(self.conv3(out))\n",
        "        out = self.primary_caps(out)\n",
        "        out = self.digit_caps(out)\n",
        "\n",
        "        # Shape of logits: (batch_size, out_capsules)\n",
        "        logits = torch.norm(out, dim=-1)\n",
        "        pred = torch.eye(7).to(device).index_select(dim=0, index=torch.argmax(logits, dim=1))\n",
        "\n",
        "        # Reconstruction\n",
        "        batch_size = out.shape[0]\n",
        "        reconstruction = self.decoder((out * pred.unsqueeze(2)).contiguous().view(batch_size, -1))\n",
        "\n",
        "        return logits, reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mshnNH3HdjAT"
      },
      "outputs": [],
      "source": [
        "class CapsuleLoss(nn.Module):\n",
        "    \"\"\"Combine margin loss & reconstruction loss of capsule network.\"\"\"\n",
        "\n",
        "    def __init__(self, upper_bound=0.9, lower_bound=0.1, lmda=0.5):\n",
        "        super(CapsuleLoss, self).__init__()\n",
        "        self.upper = upper_bound\n",
        "        self.lower = lower_bound\n",
        "        self.lmda = lmda\n",
        "        self.reconstruction_loss_scalar = 5e-3\n",
        "        self.mse = nn.MSELoss(reduction='sum')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCGXQcUidlhw"
      },
      "outputs": [],
      "source": [
        "def forward(self, images, labels, logits, reconstructions):\n",
        "        # Shape of left / right / labels: (batch_size, num_classes)\n",
        "        left = (self.upper - logits).relu() ** 2  # True negative\n",
        "        right = (logits - self.lower).relu() ** 2  # False positive\n",
        "        margin_loss = torch.sum(labels * left) + self.lmda * torch.sum((1 - labels) * right)\n",
        "\n",
        "        # Reconstruction loss\n",
        "        reconstruction_loss = self.mse(reconstructions.contiguous().view(images.shape), images)\n",
        "        self.reconstruction_loss_scalar *= 1.001\n",
        "\n",
        "        # Combine two losses\n",
        "        return margin_loss + self.reconstruction_loss_scalar * reconstruction_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YNm9lcmsSwX",
        "outputId": "8f7f6c54-2cc8-4185-8bee-19db90cdaa8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q33P3ozZduPD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import transforms\n",
        "from torch.optim import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uVIsNxSmbkM"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KYKvQM3A28-",
        "outputId": "7f52beaf-3852-4076-cc1f-983360ae5064"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/wiset\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/wiset\n",
        "!unzip -qq \"/content/drive/MyDrive/wiset/archive (1).zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8zEjyFfnCyK"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    # Load model\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "    model = CapsNet().to(device)\n",
        "    criterion = CapsuleLoss()\n",
        "    optimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.96)\n",
        "\n",
        "    # Load data\n",
        "    transform = transforms.Compose([\n",
        "        # shift by 2 pixels in either direction with zero padding.\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.RandomCrop(44, padding=1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "    BATCH_SIZE = 128\n",
        "    trainset = torchvision.datasets.ImageFolder(root=\"/content/drive/MyDrive/wiset/train\", transform=transform)\n",
        "    train_loader = DataLoader(trainset, batch_size=BATCH_SIZE, num_workers=4, shuffle=True)\n",
        "    testset = torchvision.datasets.ImageFolder(root=\"/content/drive/MyDrive/wiset/test\", transform=transform)\n",
        "    test_loader = DataLoader(testset, batch_size=BATCH_SIZE, num_workers=4, shuffle=True)\n",
        "\n",
        "    # Train\n",
        "    EPOCHES = 10\n",
        "    model.train()\n",
        "    for ep in range(EPOCHES):\n",
        "        batch_id = 1\n",
        "        correct, total, total_loss = 0, 0, 0.\n",
        "        for images, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            images = images.to(device)\n",
        "            labels = torch.eye(7).index_select(dim=0, index=labels).to(device)\n",
        "            logits, reconstruction = model(images)\n",
        "\n",
        "            # Compute loss & accuracy\n",
        "            loss = criterion(images, labels, logits, reconstruction)\n",
        "            correct += torch.sum(\n",
        "                torch.argmax(logits, dim=1) == torch.argmax(labels, dim=1)).item()\n",
        "            total += len(labels)\n",
        "            accuracy = correct / total\n",
        "            total_loss += loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            batch_id += 1\n",
        "        scheduler.step(ep)\n",
        "        print('Total loss for epoch {}: {}'.format(ep + 1, total_loss))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}